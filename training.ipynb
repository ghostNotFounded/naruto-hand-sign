{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "hand_signs = os.listdir(\"data/train\")\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for sign in hand_signs:\n",
    "    path = \"data/train/\" + sign\n",
    "    \n",
    "    for image in tqdm(os.listdir(path), desc=f\"Loading images for {sign}\"):\n",
    "        img = cv.imread(path + \"/\" + image)\n",
    "        img = cv.resize(img, (380, 380))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(sign)\n",
    "    \n",
    "print(\"\\nConverting training images to np array with float32 values scaled between 0.0 to 1.0\")\n",
    "X = np.array(images).astype(\"float32\") / 255.0\n",
    "\n",
    "print(\"\\nEncoding Y properly to a understandable format\")\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)\n",
    "\n",
    "print(\"\\nOne Hot Encoding training labels\")\n",
    "y = y.reshape(-1, 1)\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "Y = one_hot_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "def create_vgg_model(input_shape=(380,380,3), num_classes=13):\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        vgg_model = VGG16(\n",
    "            include_top=False,\n",
    "            input_shape=input_shape,\n",
    "            pooling=\"avg\",\n",
    "            weights=\"imagenet\"\n",
    "        )\n",
    "        \n",
    "        for layer in vgg_model.layers[:-4]:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        x = Flatten()(vgg_model.output)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(4096, activation=\"relu\", name=\"fc1\")(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(1024, activation=\"relu\", name=\"fc2\")(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        output = Dense(num_classes, activation=\"softmax\", name=\"predictions\")(x)\n",
    "        \n",
    "        model = Model(inputs=vgg_model.input, outputs=output, name='Sharingan')\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_signs = os.listdir(\"data/test\")\n",
    "\n",
    "images_test = []\n",
    "labels_test = []\n",
    "\n",
    "for sign in hand_signs:\n",
    "    path = \"data/test/\" + sign\n",
    "    \n",
    "    for image in tqdm(os.listdir(path), desc=f\"Loading images for {sign}\"):\n",
    "        img = cv.imread(path + \"/\" + image)\n",
    "        img = cv.resize(img, (380, 380))\n",
    "        if img is not None:\n",
    "            images_test.append(img)\n",
    "            labels_test.append(sign)\n",
    "    \n",
    "print(\"\\nConverting training images to np array with float32 values scaled between 0.0 to 1.0\")\n",
    "X_test = np.array(images_test).astype(\"float32\") / 255.0\n",
    "\n",
    "print(\"\\nEncoding Y properly to a understandable format\")\n",
    "label_encoder = LabelEncoder()\n",
    "y_test = label_encoder.fit_transform(labels_test)\n",
    "\n",
    "print(\"\\nOne Hot Encoding training labels\")\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "Y_test = one_hot_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "def train_model(model, X, Y, X_test, Y_test):\n",
    "    if issparse(X):\n",
    "        X = X.toarray()\n",
    "    if issparse(Y):\n",
    "        Y = Y.toarray() \n",
    "    if issparse(X_test):\n",
    "        X_test = X_test.toarray() \n",
    "    if issparse(Y_test):\n",
    "        Y_test = Y_test.toarray() \n",
    "    \n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    X_test = np.asarray(X_test)\n",
    "    Y_test = np.asarray(Y_test)\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        rotation_range=25,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=False,\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator()\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    batch_size = 8\n",
    "    \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', \n",
    "            factor=0.5, \n",
    "            patience=3, \n",
    "            min_lr=1e-5\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=5, \n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            './models/best_VGG_Classifier.keras', \n",
    "            save_best_only=True, \n",
    "            monitor='val_accuracy'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    train_gen = train_datagen.flow(X, Y, batch_size=batch_size)\n",
    "    val_gen = val_datagen.flow(X_test, Y_test, batch_size=batch_size)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        steps_per_epoch=len(X) // batch_size,\n",
    "        validation_steps=len(X_test) // batch_size,\n",
    "        epochs=50,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_vgg_model(num_classes=len(hand_signs))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = train_model(model, X, Y, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/final_VGG_Classifier.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
