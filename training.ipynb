{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries\n",
    "\n",
    "The recgonition model will be based on the famous CNN, VGG16 which is a 16 layer conv neural network trained on the imagenet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 15:00:08.597540: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-31 15:00:08.650886: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-31 15:00:09.055381: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-31 15:00:09.057141: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-31 15:00:10.132258: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(include_top=False,\n",
    "                        input_shape=(380,380,3),\n",
    "                        pooling=\"avg\",\n",
    "                        classes=13,\n",
    "                        weights=\"imagenet\")\n",
    "\n",
    "for layer in model.layers[:-1]:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG_Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 380, 380, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 380, 380, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 380, 380, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 190, 190, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 190, 190, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 190, 190, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 95, 95, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 95, 95, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 95, 95, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 95, 95, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 47, 47, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 47, 47, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 47, 47, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 47, 47, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 23, 23, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 23, 23, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 23, 23, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 23, 23, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 11, 11, 512)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 512)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              2101248   \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 13)                53261     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33650509 (128.37 MB)\n",
      "Trainable params: 18935821 (72.23 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Classification block, we need to add the classification block separately which will be using softmax in our case for 13 different outputs\n",
    "vgg_model = Flatten()(model.output)\n",
    "vgg_model = Dense(4096, activation=\"relu\", name=\"fc1\")(vgg_model)\n",
    "vgg_model = Dense(4096, activation=\"relu\", name=\"fc2\")(vgg_model)\n",
    "vgg_model = Dense(13, activation=\"softmax\", name=\"predictions\")(vgg_model)\n",
    "\n",
    "model = Model(model.input, vgg_model, name='VGG_Model')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "Now let's dive into the available dataset downlaoded from Kaggle with over 2000 training images for 13 different Naruto hand signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boar', 'rat', 'horse', 'dragon', 'ram', 'dog', 'hare', 'snake', 'ox', 'tiger', 'bird', 'monkey', 'zero']\n",
      "Number of Hand Signs found:  13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hand_signs = os.listdir(\"data/train\")\n",
    "print(hand_signs)\n",
    "\n",
    "print(\"Number of Hand Signs found: \", len(hand_signs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "\n",
    "for sign in hand_signs:\n",
    "    for image in os.listdir(\"data/train/\" + sign):\n",
    "        training.append((sign, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sign</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>bird</td>\n",
       "      <td>IMG_e8a75177-547b-11ea-b0af-48f17fc25591.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>boar</td>\n",
       "      <td>IMG_e880312f-547b-11ea-a08c-48f17fc25591.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>dog</td>\n",
       "      <td>IMG_e85239f0-547b-11ea-b8db-48f17fc25591.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>rat</td>\n",
       "      <td>IMG_e897cbae-547b-11ea-821a-48f17fc25591.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>hare</td>\n",
       "      <td>IMG_e8849aef-547b-11ea-899b-48f17fc25591.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sign                                         Image\n",
       "1663  bird  IMG_e8a75177-547b-11ea-b0af-48f17fc25591.png\n",
       "77    boar  IMG_e880312f-547b-11ea-a08c-48f17fc25591.png\n",
       "911    dog  IMG_e85239f0-547b-11ea-b8db-48f17fc25591.png\n",
       "176    rat  IMG_e897cbae-547b-11ea-821a-48f17fc25591.png\n",
       "1042  hare  IMG_e8849aef-547b-11ea-899b-48f17fc25591.png"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signs_df = pd.DataFrame(data=training, columns=[\"Sign\", \"Image\"])\n",
    "signs_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of hand signs:  2159\n",
      "Sign\n",
      "dog       263\n",
      "zero      199\n",
      "bird      188\n",
      "hare      174\n",
      "boar      172\n",
      "ox        169\n",
      "tiger     167\n",
      "horse     157\n",
      "dragon    146\n",
      "snake     146\n",
      "monkey    136\n",
      "rat       125\n",
      "ram       117\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of hand signs: \", len(signs_df))\n",
    "\n",
    "signs_count = signs_df[\"Sign\"].value_counts()\n",
    "\n",
    "print(signs_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images for boar: 100%|██████████| 172/172 [00:03<00:00, 56.54it/s]\n",
      "Loading images for rat: 100%|██████████| 125/125 [00:02<00:00, 58.74it/s]\n",
      "Loading images for horse: 100%|██████████| 157/157 [00:02<00:00, 59.42it/s]\n",
      "Loading images for dragon: 100%|██████████| 146/146 [00:02<00:00, 62.77it/s]\n",
      "Loading images for ram: 100%|██████████| 117/117 [00:01<00:00, 62.29it/s]\n",
      "Loading images for dog: 100%|██████████| 263/263 [00:04<00:00, 60.47it/s]\n",
      "Loading images for hare: 100%|██████████| 174/174 [00:02<00:00, 62.81it/s]\n",
      "Loading images for snake: 100%|██████████| 146/146 [00:02<00:00, 64.70it/s]\n",
      "Loading images for ox: 100%|██████████| 169/169 [00:02<00:00, 59.99it/s]\n",
      "Loading images for tiger: 100%|██████████| 167/167 [00:02<00:00, 62.02it/s]\n",
      "Loading images for bird: 100%|██████████| 188/188 [00:03<00:00, 58.49it/s]\n",
      "Loading images for monkey: 100%|██████████| 136/136 [00:02<00:00, 62.91it/s]\n",
      "Loading images for zero: 100%|██████████| 199/199 [00:03<00:00, 58.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for sign in hand_signs:\n",
    "    path = \"data/train/\" + sign\n",
    "    \n",
    "    for image in tqdm(os.listdir(path), desc=f\"Loading images for {sign}\"):\n",
    "        img = cv.imread(path + \"/\" + image)\n",
    "        img = cv.resize(img, (380, 380))\n",
    "\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2159, 380, 380, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "\n",
    "images = images.astype(\"float32\") / 255.0\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "y = signs_df[\"Sign\"].values\n",
    "\n",
    "y_labelencoder = LabelEncoder()\n",
    "y = y_labelencoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2159, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.reshape(-1, 1)\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "Y = one_hot_encoder.fit_transform(y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.convert_to_tensor(Y.todense(), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Y))\n",
    "print(type(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=1,\n",
    "                                            mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "      images,\n",
    "      Y,\n",
    "      steps_per_epoch= 2159 // 16,\n",
    "      shuffle=True,\n",
    "      epochs=10,\n",
    "      callbacks=[early_stopper],\n",
    "      use_multiprocessing=False,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"./models/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
