{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730560517045,
     "user": {
      "displayName": "ARSHEYA SINGH PARMAR",
      "userId": "14280787339759215435"
     },
     "user_tz": -330
    },
    "id": "oW61yu9Nk3n8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5230,
     "status": "ok",
     "timestamp": 1730560522272,
     "user": {
      "displayName": "ARSHEYA SINGH PARMAR",
      "userId": "14280787339759215435"
     },
     "user_tz": -330
    },
    "id": "xCGgXsV7k3n-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730823167.729307   41610 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730823167.814882   41610 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730560522272,
     "user": {
      "displayName": "ARSHEYA SINGH PARMAR",
      "userId": "14280787339759215435"
     },
     "user_tz": -330
    },
    "id": "ygFMWvzAn0iS"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_learning_curves(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation accuracy and loss curves from the model's history.\n",
    "\n",
    "    Parameters:\n",
    "    history (History): The History object returned by model.fit, which contains\n",
    "                       training and validation accuracy and loss per epoch.\n",
    "    \"\"\"\n",
    "    # Get training and validation accuracy values\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    # Get training and validation loss values\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'bo-', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'ro-', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZU0WRoIwk3n_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images for dog:  68%|██████▊   | 179/263 [00:03<00:01, 58.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/train/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m sign\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m tqdm(os\u001b[38;5;241m.\u001b[39mlistdir(path), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading images for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msign\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m380\u001b[39m))\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "hand_signs = os.listdir(\"data/train\")\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for sign in hand_signs:\n",
    "    path = \"data/train/\" + sign\n",
    "\n",
    "    for image in tqdm(os.listdir(path), desc=f\"Loading images for {sign}\"):\n",
    "        img = cv.imread(path + \"/\" + image)\n",
    "        img = cv.resize(img, (640, 380))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(sign)\n",
    "\n",
    "print(\"\\nConverting training images to np array with float32 values scaled\")\n",
    "X = np.array(images).astype(\"float32\") / 255.\n",
    "\n",
    "print(\"\\nEncoding Y properly to a understandable format\")\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)\n",
    "\n",
    "print(\"\\nOne Hot Encoding training labels\")\n",
    "y = y.reshape(-1, 1)\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "Y = one_hot_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "NZvBRQxNk3oA"
   },
   "outputs": [],
   "source": [
    "hand_signs = os.listdir(\"data/test\")\n",
    "\n",
    "images_test = []\n",
    "labels_test = []\n",
    "\n",
    "for sign in hand_signs:\n",
    "    path = \"data/test/\" + sign\n",
    "\n",
    "    for image in tqdm(os.listdir(path), desc=f\"Loading images for {sign}\"):\n",
    "        img = cv.imread(path + \"/\" + image)\n",
    "        img = cv.resize(img, (640, 380))\n",
    "        if img is not None:\n",
    "            images_test.append(img)\n",
    "            labels_test.append(sign)\n",
    "\n",
    "print(\"\\nConverting training images to np array with float32 values scaled\")\n",
    "X_test = np.array(images_test).astype(\"float32\") / 255.0\n",
    "\n",
    "print(\"\\nEncoding Y properly to a understandable format\")\n",
    "label_encoder = LabelEncoder()\n",
    "y_test = label_encoder.fit_transform(labels_test)\n",
    "\n",
    "print(\"\\nOne Hot Encoding training labels\")\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "Y_test = one_hot_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CUssMWfok3oB"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def create_vgg_model(input_shape=X[0].shape, num_classes=13):\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        vgg_model = VGG16(\n",
    "            include_top=False,\n",
    "            input_shape=input_shape,\n",
    "            pooling=\"avg\",\n",
    "            weights=\"imagenet\"\n",
    "        )\n",
    "\n",
    "        for layer in vgg_model.layers[:-5]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        x = Dense(4096, activation=\"relu\")(vgg_model.output)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(1024, activation=\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        output = Dense(num_classes, activation=\"softmax\", name=\"Prediction\")(x)\n",
    "\n",
    "        model = Model(inputs=vgg_model.input, outputs=output, name=\"Sharingan\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "o8LWG_bCk3oC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "def train_model(model, X, Y, X_test, Y_test):\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        if issparse(X):\n",
    "            X = X.toarray()\n",
    "        if issparse(Y):\n",
    "            Y = Y.toarray()\n",
    "        if issparse(X_test):\n",
    "            X_test = X_test.toarray()\n",
    "        if issparse(Y_test):\n",
    "            Y_test = Y_test.toarray()\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        Y = np.asarray(Y)\n",
    "        X_test = np.asarray(X_test)\n",
    "        Y_test = np.asarray(Y_test)\n",
    "\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            brightness_range=[0.8, 1.2],\n",
    "            preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",
    "        )\n",
    "\n",
    "        val_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        batch_size = 48\n",
    "        val_size = 32\n",
    "\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_accuracy',\n",
    "                factor=0.5,\n",
    "                patience=3,\n",
    "                min_delta=0.001,\n",
    "                min_lr=1e-9\n",
    "            ),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                './models/best_VGG_Classifier.keras',\n",
    "                save_best_only=True,\n",
    "                monitor='val_accuracy'\n",
    "            ),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=10,\n",
    "                min_delta=0.001,\n",
    "                mode='min'\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        train_gen = train_datagen.flow(X, Y, batch_size=batch_size)\n",
    "        val_gen = val_datagen.flow(X_test, Y_test, batch_size=val_size)\n",
    "\n",
    "        history = model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            steps_per_epoch=len(X) // batch_size,\n",
    "            validation_steps=None,\n",
    "            epochs=100,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pw-wEjeRk3oC"
   },
   "outputs": [],
   "source": [
    "model = create_vgg_model(num_classes=len(hand_signs))\n",
    "model.summary()\n",
    "history = train_model(model, X, Y, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPGKN41R3v3K"
   },
   "outputs": [],
   "source": [
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKgD4CH4k3oD"
   },
   "outputs": [],
   "source": [
    "model.save(\"./models/final_VGG_Classifier.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEKtsQUfk3oD"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
